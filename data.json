[
  {
    "id": "http://arxiv.org/abs/2512.20299v1",
    "title": "KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System",
    "date": "2025-12-23",
    "tag": "自动驾驶",
    "summary": "这篇论文提出了一种名为KnowVal的新型自动驾驶系统，通过整合开放世界感知与知识检索，实现视觉-语言推理，以解决现有方法依赖数据驱动学习、难以捕捉复杂决策逻辑的问题。具体贡献包括：\n\n1. **构建驾驶知识图谱**：整合交通法规、防御性驾驶原则和伦理规范。\n2. **设计基于LLM的检索机制**：针对驾驶场景高效检索相关知识。\n3. **开发价值对齐模型**：通过人类偏好数据集训练价值模型，指导可解释且符合人类价值观的轨迹评估。\n\n实验结果表明，KnowVal在nuScenes数据集上实现了最低碰撞率，在Bench2Drive基准测试中达到最优性能，同时与现有架构兼容。",
    "raw_summary": "Visual-language reasoning, driving knowledge, and value alignment are essential for advanced autonomous driving systems. However, existing approaches largely rely on data-driven learning, making it difficult to capture the complex logic underlying decision-making through imitation or limited reinforcement rewards. To address this, we propose KnowVal, a new autonomous driving system that enables visual-language reasoning through the synergistic integration of open-world perception and knowledge retrieval. Specifically, we construct a comprehensive driving knowledge graph that encodes traffic laws, defensive driving principles, and ethical norms, complemented by an efficient LLM-based retrieval mechanism tailored for driving scenarios. Furthermore, we develop a human-preference dataset and train a Value Model to guide interpretable, value-aligned trajectory assessment. Experimental results show that our method substantially improves planning performance while remaining compatible with existing architectures. Notably, KnowVal achieves the lowest collision rate on nuScenes and state-of-the-art results on Bench2Drive.",
    "link": "https://arxiv.org/pdf/2512.20299v1"
  },
  {
    "id": "http://arxiv.org/abs/2512.20224v1",
    "title": "UrbanV2X: A Multisensory Vehicle-Infrastructure Dataset for Cooperative Navigation in Urban Areas",
    "date": "2025-12-23",
    "tag": "自动驾驶",
    "summary": "这篇论文介绍了名为UrbanV2X的数据集，旨在解决车路协同自动驾驶研究中真实世界数据稀缺的问题。该数据集在香港C-V2X测试场采集，包含车辆和路边基础设施的多传感器同步数据，如摄像头、激光雷达、4D雷达、UWB、IMU和高精度定位系统。所有数据通过精密时间协议同步，并提供了传感器标定信息。研究团队还利用该数据集对多种导航算法进行了基准测试。数据集已公开。",
    "raw_summary": "Due to the limitations of a single autonomous vehicle, Cellular Vehicle-to-Everything (C-V2X) technology opens a new window for achieving fully autonomous driving through sensor information sharing. However, real-world datasets supporting vehicle-infrastructure cooperative navigation in complex urban environments remain rare. To address this gap, we present UrbanV2X, a comprehensive multisensory dataset collected from vehicles and roadside infrastructure in the Hong Kong C-V2X testbed, designed to support research on smart mobility applications in dense urban areas. Our onboard platform provides synchronized data from multiple industrial cameras, LiDARs, 4D radar, ultra-wideband (UWB), IMU, and high-precision GNSS-RTK/INS navigation systems. Meanwhile, our roadside infrastructure provides LiDAR, GNSS, and UWB measurements. The entire vehicle-infrastructure platform is synchronized using the Precision Time Protocol (PTP), with sensor calibration data provided. We also benchmark various navigation algorithms to evaluate the collected cooperative data. The dataset is publicly available at https://polyu-taslab.github.io/UrbanV2X/.",
    "link": "https://arxiv.org/pdf/2512.20224v1"
  },
  {
    "id": "http://arxiv.org/abs/2512.19347v1",
    "title": "OMP: One-step Meanflow Policy with Directional Alignment",
    "date": "2025-12-22",
    "tag": "自动驾驶",
    "summary": "这篇论文针对机器人操作任务中现有生成式策略框架（如扩散模型推理延迟高、流方法结构复杂）的不足，提出了一种改进的基于MeanFlow的策略方法。主要创新点包括：\n\n1. **引入轻量级余弦损失**：对齐预测与真实速度方向，解决原有方法中速度方向不一致的问题。\n2. **采用微分推导方程优化JVP算子**：提升计算效率与准确性。\n\n实验在Adroit和Meta-World任务上进行，结果显示该方法在平均成功率上优于MP1和FlowPolicy，尤其在复杂任务中表现出更强的**小样本泛化能力**与**轨迹精度**，同时保持了实时性能，为高精度机器人操作提供了更鲁棒的解决方案。",
    "raw_summary": "Robot manipulation, a key capability of embodied AI, has turned to data-driven generative policy frameworks, but mainstream approaches like Diffusion Models suffer from high inference latency and Flow-based Methods from increased architectural complexity. While simply applying meanFlow on robotic tasks achieves single-step inference and outperforms FlowPolicy, it lacks few-shot generalization due to fixed temperature hyperparameters in its Dispersive Loss and misaligned predicted-true mean velocities. To solve these issues, this study proposes an improved MeanFlow-based Policies: we introduce a lightweight Cosine Loss to align velocity directions and use the Differential Derivation Equation (DDE) to optimize the Jacobian-Vector Product (JVP) operator. Experiments on Adroit and Meta-World tasks show the proposed method outperforms MP1 and FlowPolicy in average success rate, especially in challenging Meta-World tasks, effectively enhancing few-shot generalization and trajectory accuracy of robot manipulation policies while maintaining real-time performance, offering a more robust solution for high-precision robotic manipulation.",
    "link": "https://arxiv.org/pdf/2512.19347v1"
  },
  {
    "id": "http://arxiv.org/abs/2512.19270v1",
    "title": "Are All Data Necessary? Efficient Data Pruning for Large-scale Autonomous Driving Dataset via Trajectory Entropy Maximization",
    "date": "2025-12-22",
    "tag": "自动驾驶",
    "summary": "本文提出了一种基于信息论的驾驶数据剪枝方法，旨在解决大规模自然驾驶数据集中存在大量重复、低价值样本的问题。该方法通过评估驾驶数据的轨迹分布信息熵，以模型无关的方式迭代选择能够保持原始数据集统计特征的高价值样本，从而在保证模型性能的前提下有效减少训练数据量。\n\n理论分析表明，最大化轨迹熵能够约束剪枝后子集与原始数据分布之间的KL散度，从而保持模型的泛化能力。在NuPlan基准测试中，结合大规模模仿学习框架的实验表明，该方法能够将数据集规模减少高达40%，同时保持闭环驾驶性能不变。\n\n这项工作为自动驾驶系统的可扩展数据管理和高效策略学习提供了一种轻量化且理论依据充分的方法。",
    "raw_summary": "Collecting large-scale naturalistic driving data is essential for training robust autonomous driving planners. However, real-world datasets often contain a substantial amount of repetitive and low-value samples, which lead to excessive storage costs and bring limited benefits to policy learning. To address this issue, we propose an information-theoretic data pruning method that effectively reduces the training data volume without compromising model performance. Our approach evaluates the trajectory distribution information entropy of driving data and iteratively selects high-value samples that preserve the statistical characteristics of the original dataset in a model-agnostic manner. From a theoretical perspective, we show that maximizing trajectory entropy effectively constrains the Kullback-Leibler divergence between the pruned subset and the original data distribution, thereby maintaining generalization ability. Comprehensive experiments on the NuPlan benchmark with a large-scale imitation learning framework demonstrate that the proposed method can reduce the dataset size by up to 40% while maintaining closed-loop performance. This work provides a lightweight and theoretically grounded approach for scalable data management and efficient policy learning in autonomous driving systems.",
    "link": "https://arxiv.org/pdf/2512.19270v1"
  },
  {
    "id": "http://arxiv.org/abs/2512.19133v1",
    "title": "WorldRFT: Latent World Model Planning with Reinforcement Fine-Tuning for Autonomous Driving",
    "date": "2025-12-22",
    "tag": "自动驾驶",
    "summary": "这篇论文提出了一种名为WorldRFT的面向规划的隐式世界模型框架，旨在解决现有端到端自动驾驶模型中感知与规划任务耦合导致的优化问题。其主要创新点包括：\n\n1. **核心方法**：通过分层规划任务分解和局部感知交互优化机制，使场景表征学习与规划任务对齐，并采用强化学习微调（RFT）提升策略安全性。\n2. **技术亮点**：\n   - 引入视觉-几何基础模型增强3D空间感知能力；\n   - 提出分组相对策略优化（GRPO），结合轨迹高斯化和碰撞感知奖励微调驾驶策略。\n3. **性能表现**：\n   - 在nuScenes数据集上，碰撞率降低83%（从0.30%降至0.05%）；\n   - 在NavSim仿真中，仅使用摄像头输入即达到与激光雷达SOTA方法（DiffusionDrive）相近的性能（PDMS评分87.8 vs. 88.1）。\n\n该框架实现了无需感知标注的端到端自动驾驶，并在开放与闭环测试中均取得领先效果。",
    "raw_summary": "Latent World Models enhance scene representation through temporal self-supervised learning, presenting a perception annotation-free paradigm for end-to-end autonomous driving. However, the reconstruction-oriented representation learning tangles perception with planning tasks, leading to suboptimal optimization for planning. To address this challenge, we propose WorldRFT, a planning-oriented latent world model framework that aligns scene representation learning with planning via a hierarchical planning decomposition and local-aware interactive refinement mechanism, augmented by reinforcement learning fine-tuning (RFT) to enhance safety-critical policy performance. Specifically, WorldRFT integrates a vision-geometry foundation model to improve 3D spatial awareness, employs hierarchical planning task decomposition to guide representation optimization, and utilizes local-aware iterative refinement to derive a planning-oriented driving policy. Furthermore, we introduce Group Relative Policy Optimization (GRPO), which applies trajectory Gaussianization and collision-aware rewards to fine-tune the driving policy, yielding systematic improvements in safety. WorldRFT achieves state-of-the-art (SOTA) performance on both open-loop nuScenes and closed-loop NavSim benchmarks. On nuScenes, it reduces collision rates by 83% (0.30% -> 0.05%). On NavSim, using camera-only sensors input, it attains competitive performance with the LiDAR-based SOTA method DiffusionDrive (87.8 vs. 88.1 PDMS).",
    "link": "https://arxiv.org/pdf/2512.19133v1"
  },
  {
    "id": "http://arxiv.org/abs/2512.19024v1",
    "title": "IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments",
    "date": "2025-12-22",
    "tag": "自动驾驶",
    "summary": "这篇论文提出了 **IndoorUAV**，一个专门为室内无人机视觉语言导航（VLN）设计的新基准和方法。\n\n**核心问题**：现有VLN研究主要针对地面机器人或室外无人机，而室内无人机VLN（在检查、送货、搜救等场景中应用广泛）尚未得到充分探索。\n\n**主要贡献**：\n1.  **构建新基准**：从Habitat模拟器中选取了1000多个多样化的3D室内场景，通过模拟真实无人机飞行动力学，手动收集并增强数据，生成了超过16,000条高质量导航轨迹。\n2.  **自动生成指令**：设计了自动化标注流程，为每条轨迹生成不同精细程度的自然语言指令。\n3.  **两个子数据集**：\n    *   **IndoorUAV-VLN**：专注于**长视野**导航任务。\n    *   **IndoorUAV-VLA**：通过选择语义关键帧分割长轨迹并重新生成简洁指令，专注于**短视野**规划任务。\n4.  **提出新模型**：引入了 **IndoorUAV-Agent** 导航模型，该模型利用任务分解和多模态推理，专门为所提出的基准设计。\n\n**目标**：希望IndoorUAV能成为推动室内空中导航领域视觉语言具身AI研究的重要资源。",
    "raw_summary": "Vision-Language Navigation (VLN) enables agents to navigate in complex environments by following natural language instructions grounded in visual observations. Although most existing work has focused on ground-based robots or outdoor Unmanned Aerial Vehicles (UAVs), indoor UAV-based VLN remains underexplored, despite its relevance to real-world applications such as inspection, delivery, and search-and-rescue in confined spaces. To bridge this gap, we introduce \\textbf{IndoorUAV}, a novel benchmark and method specifically tailored for VLN with indoor UAVs. We begin by curating over 1,000 diverse and structurally rich 3D indoor scenes from the Habitat simulator. Within these environments, we simulate realistic UAV flight dynamics to collect diverse 3D navigation trajectories manually, further enriched through data augmentation techniques. Furthermore, we design an automated annotation pipeline to generate natural language instructions of varying granularity for each trajectory. This process yields over 16,000 high-quality trajectories, comprising the \\textbf{IndoorUAV-VLN} subset, which focuses on long-horizon VLN. To support short-horizon planning, we segment long trajectories into sub-trajectories by selecting semantically salient keyframes and regenerating concise instructions, forming the \\textbf{IndoorUAV-VLA} subset. Finally, we introduce \\textbf{IndoorUAV-Agent}, a novel navigation model designed for our benchmark, leveraging task decomposition and multimodal reasoning. We hope IndoorUAV serves as a valuable resource to advance research on vision-language embodied AI in the indoor aerial navigation domain.",
    "link": "https://arxiv.org/pdf/2512.19024v1"
  },
  {
    "id": "http://arxiv.org/abs/2512.19021v1",
    "title": "VLNVerse: A Benchmark for Vision-Language Navigation with Versatile, Embodied, Realistic Simulation and Evaluation",
    "date": "2025-12-22",
    "tag": "具身智能",
    "summary": "这篇论文介绍了**VLNVerse**，一个用于视觉语言导航（VLN）的新型大规模、可扩展基准测试平台。针对现有VLN基准数据集规模小、物理模拟简单、任务分散且数据量不足以支持大语言模型预训练等问题，VLNVerse旨在重新定义VLN为一个可扩展、全栈的具身人工智能问题。\n\nVLNVerse的核心特点包括：\n1.  **多功能与统一性**：将以往分散的任务整合到单一框架中，并提供可扩展的研究工具包。\n2.  **具身化设计**：支持具备完整运动学的实体智能体，超越了以往“无形”或“瞬移”的虚拟智能体。\n3.  **真实模拟**：基于强大的物理引擎实现逼真的环境模拟。\n4.  **大规模评估**：利用其规模和多样性，对从经典模型到基于多模态大语言模型的智能体进行了全面评估。\n\n此外，论文还提出了一种新颖的统一多任务模型，能够处理基准测试中的所有任务。VLNVerse的目标是缩小模拟导航与现实世界泛化能力之间的差距，为研究界提供一个推动可扩展、通用具身移动智能体研究的重要工具。",
    "raw_summary": "Despite remarkable progress in Vision-Language Navigation (VLN), existing benchmarks remain confined to fixed, small-scale datasets with naive physical simulation. These shortcomings limit the insight that the benchmarks provide into sim-to-real generalization, and create a significant research gap. Furthermore, task fragmentation prevents unified/shared progress in the area, while limited data scales fail to meet the demands of modern LLM-based pretraining. To overcome these limitations, we introduce VLNVerse: a new large-scale, extensible benchmark designed for Versatile, Embodied, Realistic Simulation, and Evaluation. VLNVerse redefines VLN as a scalable, full-stack embodied AI problem. Its Versatile nature unifies previously fragmented tasks into a single framework and provides an extensible toolkit for researchers. Its Embodied design moves beyond intangible and teleporting \"ghost\" agents that support full-kinematics in a Realistic Simulation powered by a robust physics engine. We leverage the scale and diversity of VLNVerse to conduct a comprehensive Evaluation of existing methods, from classic models to MLLM-based agents. We also propose a novel unified multi-task model capable of addressing all tasks within the benchmark. VLNVerse aims to narrow the gap between simulated navigation and real-world generalization, providing the community with a vital tool to boost research towards scalable, general-purpose embodied locomotion agents.",
    "link": "https://arxiv.org/pdf/2512.19021v1"
  },
  {
    "id": "http://arxiv.org/abs/2512.18850v1",
    "title": "InDRiVE: Reward-Free World-Model Pretraining for Autonomous Driving via Latent Disagreement",
    "date": "2025-12-21",
    "tag": "自动驾驶",
    "summary": "这篇论文提出了一种名为InDRiVE的模型强化学习（MBRL）方法，用于自动驾驶任务。该方法基于DreamerV3框架，通过内在动机（即潜在集成分歧）进行无奖励预训练，无需依赖人工设计的任务奖励。分歧作为认知不确定性的代理，引导智能体探索未充分研究的驾驶场景，同时基于想象的行动者-评论家直接从学习的世界模型中学习无规划器的探索策略。\n\n预训练后，研究通过冻结所有参数，在未见过的城镇和路线上部署预训练的探索策略，评估其零样本迁移能力。此外，论文还研究了少样本适应，即使用有限的外部反馈训练任务策略，以实现下游目标（如车道跟随和碰撞避免）。\n\n在CARLA模拟器中的实验表明，基于分歧的预训练在城镇变化和相同交互预算下，表现出更强的零样本鲁棒性和稳健的少样本碰撞避免能力，支持将内在分歧作为可重用驾驶世界模型的实用无奖励预训练信号。",
    "raw_summary": "Model-based reinforcement learning (MBRL) can reduce interaction cost for autonomous driving by learning a predictive world model, but it typically still depends on task-specific rewards that are difficult to design and often brittle under distribution shift. This paper presents InDRiVE, a DreamerV3-style MBRL agent that performs reward-free pretraining in CARLA using only intrinsic motivation derived from latent ensemble disagreement. Disagreement acts as a proxy for epistemic uncertainty and drives the agent toward under-explored driving situations, while an imagination-based actor-critic learns a planner-free exploration policy directly from the learned world model. After intrinsic pretraining, we evaluate zero-shot transfer by freezing all parameters and deploying the pretrained exploration policy in unseen towns and routes. We then study few-shot adaptation by training a task policy with limited extrinsic feedback for downstream objectives (lane following and collision avoidance). Experiments in CARLA across towns, routes, and traffic densities show that disagreement-based pretraining yields stronger zero-shot robustness and robust few-shot collision avoidance under town shift and matched interaction budgets, supporting the use of intrinsic disagreement as a practical reward-free pretraining signal for reusable driving world models.",
    "link": "https://arxiv.org/pdf/2512.18850v1"
  },
  {
    "id": "http://arxiv.org/abs/2512.18703v1",
    "title": "CauTraj: A Causal-Knowledge-Guided Framework for Lane-Changing Trajectory Planning of Autonomous Vehicles",
    "date": "2025-12-21",
    "tag": "自动驾驶",
    "summary": "本文提出了一种集成因果先验知识的轨迹规划框架，旨在提升自动驾驶车辆在混合交通环境中的换道性能。传统方法在设计轨迹规划模型时往往忽略人类驾驶员的先验知识，本研究通过构建分阶段因果图来量化换道场景中车辆间的交互风险，并利用因果推断（包括平均因果效应ATE和条件平均处理效应CATE）估计换道车辆与周围车辆的因果效应。这些因果先验知识被嵌入模型预测控制（MPC）框架中，以优化轨迹规划。基于真实车辆轨迹数据集的实验表明：该方法能可解释且稳定地量化车辆交互，揭示驾驶员异质性；与基准MPC相比，所提方法更贴近人类驾驶行为，最大轨迹偏差从1.2米降至0.2米，横向速度波动减少60%，横摆角变化降低50%。该研究为类人轨迹规划提供了方法支持，对提升自动驾驶测试与交通仿真的安全性、稳定性和真实性具有实用价值。",
    "raw_summary": "Enhancing the performance of trajectory planners for lane - changing vehicles is one of the key challenges in autonomous driving within human - machine mixed traffic. Most existing studies have not incorporated human drivers' prior knowledge when designing trajectory planning models. To address this issue, this study proposes a novel trajectory planning framework that integrates causal prior knowledge into the control process. Both longitudinal and lateral microscopic behaviors of vehicles are modeled to quantify interaction risk, and a staged causal graph is constructed to capture causal dependencies in lane-changing scenarios. Causal effects between the lane-changing vehicle and surrounding vehicles are then estimated using causal inference, including average causal effects (ATE) and conditional average treatment effects (CATE). These causal priors are embedded into a model predictive control (MPC) framework to enhance trajectory planning. The proposed approach is validated on naturalistic vehicle trajectory datasets. Experimental results show that: (1) causal inference provides interpretable and stable quantification of vehicle interactions; (2) individual causal effects reveal driver heterogeneity; and (3) compared with the baseline MPC, the proposed method achieves a closer alignment with human driving behaviors, reducing maximum trajectory deviation from 1.2 m to 0.2 m, lateral velocity fluctuation by 60%, and yaw angle variability by 50%. These findings provide methodological support for human-like trajectory planning and practical value for improving safety, stability, and realism in autonomous vehicle testing and traffic simulation platforms.",
    "link": "https://arxiv.org/pdf/2512.18703v1"
  },
  {
    "id": "http://arxiv.org/abs/2512.18662v1",
    "title": "Offline Reinforcement Learning for End-to-End Autonomous Driving",
    "date": "2025-12-21",
    "tag": "自动驾驶",
    "summary": "这篇论文提出了一种仅使用摄像头输入的端到端自动驾驶模型新框架，旨在解决传统模仿学习（IL）方法的局限性。主要创新点包括：\n\n1. **问题背景**：现有端到端模型依赖模仿学习，存在固有缺陷；在线强化学习（RL）虽能改善问题，但计算成本高昂。\n\n2. **核心方法**：提出一种**仅用摄像头的离线强化学习框架**，无需额外探索，仅使用固定模拟器数据集进行训练。该方法通过**行为正则化**缓解离线RL中因分布外动作导致的估值过高问题，具体做法是利用专家驾驶日志构建伪真实轨迹，抑制不安全或次优行为模仿。\n\n3. **实验验证**：在基于nuScenes数据集构建的神经渲染环境中进行训练与闭环测试，结果显示该方法在**碰撞率与路线完成率**上显著优于模仿学习基线。\n\n4. **优势**：兼顾数据效率与实验迭代速度，同时提升驾驶安全性与性能。\n\n论文代码将公开提供。",
    "raw_summary": "End-to-end (E2E) autonomous driving models that take only camera images as input and directly predict a future trajectory are appealing for their computational efficiency and potential for improved generalization via unified optimization; however, persistent failure modes remain due to reliance on imitation learning (IL). While online reinforcement learning (RL) could mitigate IL-induced issues, the computational burden of neural rendering-based simulation and large E2E networks renders iterative reward and hyperparameter tuning costly. We introduce a camera-only E2E offline RL framework that performs no additional exploration and trains solely on a fixed simulator dataset. Offline RL offers strong data efficiency and rapid experimental iteration, yet is susceptible to instability from overestimation on out-of-distribution (OOD) actions. To address this, we construct pseudo ground-truth trajectories from expert driving logs and use them as a behavior regularization signal, suppressing imitation of unsafe or suboptimal behavior while stabilizing value learning. Training and closed-loop evaluation are conducted in a neural rendering environment learned from the public nuScenes dataset. Empirically, the proposed method achieves substantial improvements in collision rate and route completion compared with IL baselines. Our code will be available at [URL].",
    "link": "https://arxiv.org/pdf/2512.18662v1"
  }
]